const terms = {
	"moduleOne": [
		{
			"front": "prompt",
			"back": "specific instructions, directions or queries to interact with AI",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "prompt engineering",
			"back": "a system of designing the most optimal prompts to achieve the desired outcome",
			"backgroundColor": "bg-gray-500",
			"borderColor": "border-gray-500",
			"textColor": "text-gray-100"
		},
		{
			"front": "completion",
			"back": "The text response provided by an LLM to the user's request",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "zero-shot prompt",
			"back": "prompt with no outcome examples",
			"backgroundColor": "bg-blue-300",
			"borderColor": "border-blue-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "one-shot prompt",
			"back": "prompt with one output example",
			"backgroundColor": "bg-gray-800",
			"borderColor": "border-gray-800",
			"textColor": "text-gray-100"
		},
		{
			"front": "few-shot prompt",
			"back": "prompt with several output examples",
			"backgroundColor": "bg-gray-300",
			"borderColor": "border-gray-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "meta-prompting",
			"back": "a technique approach to improve how prompts are formulated to achieve better outcomes",
			"backgroundColor": "bg-pink-300",
			"borderColor": "border-pink-300",
			"textColor": "text-gray-800"
		},
		{
			"front": "temperature",
			"back": "A setting to control the diversity and randomness of the output",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "Top P",
			"back": "A setting to directly limit or expand the pool of available words",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "Max Length",
			"back": "Maximum number of tokens allowed to generate",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "Stop Sequences",
			"back": "A string that stops the model from generating more tokens",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "Frequency Penalty",
			"back": "A parameter that applies a penalty directly proportional to how many times the word has already appeared",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    },
		{
			"front": "Presence Penalty",
			"back": "A parameter that applies a penalty to a word despite its frequency, even if it occured once",
			"backgroundColor": "bg-yellow-300",
			"borderColor": "border-yellow-300",
			"textColor": "text-gray-800"
	    }
	]
}

export default terms